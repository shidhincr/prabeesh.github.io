<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[This is One of the Solutions]]></title>
  <link href="http://blog.prabeeshk.com/atom.xml" rel="self"/>
  <link href="http://blog.prabeeshk.com/"/>
  <updated>2015-02-24T23:22:00+05:30</updated>
  <id>http://blog.prabeeshk.com/</id>
  <author>
    <name><![CDATA[Prabeesh K]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Install Apache Spark on Ubuntu-14.04]]></title>
    <link href="http://blog.prabeeshk.com/blog/2014/10/31/install-apache-spark-on-ubuntu-14-dot-04/"/>
    <updated>2014-10-31T13:58:31+05:30</updated>
    <id>http://blog.prabeeshk.com/blog/2014/10/31/install-apache-spark-on-ubuntu-14-dot-04</id>
    <content type="html"><![CDATA[<p>On of the <a href="http://blog.prabeeshk.com/blog/2013/11/26/installing-apache-spark-on-ubuntu-1204/">previous post</a> mentioning about install Spark-0.8.0 in Ubuntu-12.04. In this post  explain about detailed steps to set up Spark-1.1.0 in  Ubuntu machine. For running Spark in Ubuntu machine should install Java.  Using following commands  easily install Java in Ubuntu machine.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sudo apt-add-repository ppa:webupd8team/java
</span><span class='line'>$ sudo apt-get update
</span><span class='line'>$ sudo apt-get install oracle-java7-installer</span></code></pre></td></tr></table></div></figure>


<p> To check the Java installation is successful</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ java -version</span></code></pre></td></tr></table></div></figure>


<p>It shows installed java version</p>

<p><code>
java version "1.7.0_72"_
Java(TM) SE Runtime Environment (build 1.7.0_72-b14)_
Java HotSpot(TM) 64-Bit Server VM (build 24.72-b04, mixed mode)
</code></p>

<p>In next step is install Scala, follow the following
instructions to set up Scala. First download the Scala from <a href="http://www.scala-lang.org/download/2.10.4.html">here</a></p>

<p>Copy downloaded file to some location for example <em>/urs/local/src</em>,
untar the file and set path variable,</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ wget http://www.scala-lang.org/files/archive/scala-2.10.4.tgz
</span><span class='line'>$ sudo mkdir /usr/local/src/scala
</span><span class='line'>$ sudo cp scala-2.10.4.tgz /usr/local/src/scala
</span><span class='line'>$ sudo tar xvf /usr/local/src/scala-2.10.4.tgz</span></code></pre></td></tr></table></div></figure>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ vi .bashrc</span></code></pre></td></tr></table></div></figure>


<p>And add following in the end of the file</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>export SCALA_HOME=/usr/local/src/scala/scala-2.10.4
</span><span class='line'>export PATH=$SCALA_HOME/bin:$PATH</span></code></pre></td></tr></table></div></figure>


<p>restart bashrc</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ . .bashrc</span></code></pre></td></tr></table></div></figure>


<p>To check the Scala is successful</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ scala -version</span></code></pre></td></tr></table></div></figure>


<p>It shows installed Scala version
<code>
Scala code runner version 2.10.4 -- Copyright 2002-2013, LAMP/EPFL
</code></p>

<p>Or just type scala. It goes to scala interactive shell</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ scala
</span><span class='line'>scala&gt;</span></code></pre></td></tr></table></div></figure>


<p>Finally download spark ditributaion from <a href="http://d3kbcqa49mib13.cloudfront.net/spark-1.1.0.tgz">here</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ wget http://d3kbcqa49mib13.cloudfront.net/spark-1.1.0.tgz
</span><span class='line'>$ tar xvf spark-1.1.0.tgz </span></code></pre></td></tr></table></div></figure>


<h3>Building</h3>

<p>SBT(Simple Build Tool) is used for building Spark, which is bundled with it. To compile the code</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ cd spark-1.1.0
</span><span class='line'>
</span><span class='line'>$ sbt/sbt assembly</span></code></pre></td></tr></table></div></figure>


<p>Building take some time. After successfully packing you can test a sample program</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ ./bin/run-example SparkPi 10</span></code></pre></td></tr></table></div></figure>


<p>Then you get the output as Pi is roughly 3.14634. Spark is ready to fire</p>

<p>For more detail <a href="http://spark.apache.org/docs/1.1.1/">visit</a></p>

<h3>Spark Interactive Shell</h3>

<p>You can run Spark interactively through the Scala shell</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ ./spark-shell</span></code></pre></td></tr></table></div></figure>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="n">textFile</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;README.md&quot;</span><span class="o">)</span>
</span><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="n">textFile</span><span class="o">.</span><span class="n">count</span><span class="o">()</span>
</span></code></pre></td></tr></table></div></figure>


<p>If want to check some particular sections of spark using shell. For example run MQTT interactevely, the mqtt is defined under external for import that into <em>spark-shell</em> just follow the instructions</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">$</span> <span class="n">sbt</span><span class="o">/</span><span class="n">sbt</span> <span class="s">&quot;streaming-mqtt/package&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="n">then</span> <span class="n">add</span> <span class="k">this</span> <span class="k">package</span> <span class="nn">into</span> <span class="n">the</span> <span class="n">classpath</span><span class="k">:</span>
</span><span class='line'>
</span><span class='line'><span class="kt">$</span> <span class="kt">bin/spark-shell</span> <span class="kt">--driver-class-path</span>
</span><span class='line'><span class="n">external</span><span class="o">/</span><span class="n">mqtt</span><span class="o">/</span><span class="n">target</span><span class="o">/</span><span class="n">scala</span><span class="o">-</span><span class="mf">2.10</span><span class="o">/</span><span class="n">spark</span><span class="o">-</span><span class="n">streaming</span><span class="o">-</span><span class="n">mqtt_2</span><span class="o">.</span><span class="mi">10</span><span class="o">-</span><span class="mf">1.1</span><span class="o">.</span><span class="mf">0.</span><span class="n">jar</span>
</span><span class='line'><span class="n">scala</span> <span class="o">&gt;</span> <span class="k">import</span> <span class="nn">org.apache.spark.streaming.mqtt._</span>
</span></code></pre></td></tr></table></div></figure>


<p>Using this you can check your code line by line.</p>

<h3>Accessing Hadoop Filesystems</h3>

<p>If you have already the build source package, rebuild it against the hadoop version as follows</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">$</span> <span class="n">sbt</span><span class="o">/</span><span class="n">sbt</span> <span class="n">clean</span>
</span></code></pre></td></tr></table></div></figure>


<p>You can change this by setting the SPARK_HADOOP_VERSION variable. Here uses Hadoop 2.0.0-cdh4.3.0</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">$</span> <span class="nc">SPARK_HADOOP_VERSION</span><span class="k">=</span><span class="mf">2.0</span><span class="o">.</span><span class="mi">0</span><span class="o">-</span><span class="n">mr1</span><span class="o">-</span><span class="n">cdh4</span><span class="o">.</span><span class="mf">3.0</span> <span class="n">sbt</span><span class="o">/</span><span class="n">sbt</span> <span class="n">assembly</span>
</span></code></pre></td></tr></table></div></figure>


<p>After successfully build. You can read  and write data into cdh4.3.0 clusters.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">$</span> <span class="o">.</span><span class="n">bin</span><span class="o">/</span><span class="n">spark</span><span class="o">-</span><span class="n">shell</span>
</span></code></pre></td></tr></table></div></figure>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="k">var</span> <span class="n">file</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;hdfs://IP:8020/path/to/textfile.txt&quot;</span><span class="o">)</span>
</span><span class='line'><span class="n">scala</span><span class="o">&gt;</span>  <span class="n">file</span><span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot;,&quot;</span><span class="o">)).</span><span class="n">map</span><span class="o">(</span><span class="n">word</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">word</span><span class="o">,</span> <span class="mi">1</span><span class="o">)).</span><span class="n">reduceByKey</span><span class="o">(</span><span class="k">_</span><span class="o">+</span><span class="k">_</span><span class="o">)</span>
</span><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="n">count</span><span class="o">.</span><span class="n">saveAsTextFile</span><span class="o">(</span><span class="s">&quot;hdfs://IP:8020/path/to/ouput&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>You may find more <a href="http://spark.apache.org/docs/1.1.1/quick-start.html">here</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Creating Assembled JAR for Standalone Spark Application]]></title>
    <link href="http://blog.prabeeshk.com/blog/2014/04/08/creating-uber-jar-for-spark-project-using-sbt-assembly/"/>
    <updated>2014-04-08T09:47:00+05:30</updated>
    <id>http://blog.prabeeshk.com/blog/2014/04/08/creating-uber-jar-for-spark-project-using-sbt-assembly</id>
    <content type="html"><![CDATA[<p>In the <a href="http://blog.prabeeshk.com/blog/2014/04/01/a-standalone-spark-application-in-scala/">previous post</a> shared how to use sbt in Spark-streaming project. This post is about how to create a fat jar for spark streaming project using sbt plugin. sbt-assembly is a sbt plugin to create a fat JAR of sbt project with all of its dependencies.</p>

<p>Add sbt-assembly plugin in <strong><em>project/plugin.sbt</em></strong></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">addSbtPlugin</span><span class="o">(</span><span class="s">&quot;com.eed3si9n&quot;</span> <span class="o">%</span> <span class="s">&quot;sbt-assembly&quot;</span> <span class="o">%</span> <span class="s">&quot;0.9.1&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Specify sbt-assembly.git as a dependency in project/project/build.scala</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">import</span> <span class="nn">sbt._</span>
</span><span class='line'>
</span><span class='line'><span class="k">object</span> <span class="nc">Plugins</span> <span class="k">extends</span> <span class="nc">Build</span> <span class="o">{</span>
</span><span class='line'>  <span class="k">lazy</span> <span class="k">val</span> <span class="n">root</span> <span class="k">=</span> <span class="nc">Project</span><span class="o">(</span><span class="s">&quot;root&quot;</span><span class="o">,</span> <span class="n">file</span><span class="o">(</span><span class="s">&quot;.&quot;</span><span class="o">))</span> <span class="n">dependsOn</span><span class="o">(</span>
</span><span class='line'>    <span class="n">uri</span><span class="o">(</span><span class="s">&quot;git://github.com/sbt/sbt-assembly.git#0.9.1&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="o">)</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>In build.sbt file add the following contents</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">import</span> <span class="nn">AssemblyKeys._</span> <span class="c1">// put this at the top of the file,leave the next line blank</span>
</span><span class='line'>
</span><span class='line'><span class="n">assemblySettings</span>
</span></code></pre></td></tr></table></div></figure>


<p>Use full keys to configure the assembly plugin. For more details <a href="https://github.com/sbt/sbt-assembly">refer</a></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">target</span>                        <span class="n">assembly</span><span class="o">-</span><span class="n">jar</span><span class="o">-</span><span class="n">name</span>             <span class="n">test</span>
</span><span class='line'><span class="n">assembly</span><span class="o">-</span><span class="n">option</span>               <span class="n">main</span><span class="o">-</span><span class="k">class</span>                    <span class="nc">full</span><span class="o">-</span><span class="n">classpath</span>
</span><span class='line'><span class="n">dependency</span><span class="o">-</span><span class="n">classpath</span>          <span class="n">assembly</span><span class="o">-</span><span class="n">excluded</span><span class="o">-</span><span class="n">files</span>       <span class="n">assembly</span><span class="o">-</span><span class="n">excluded</span><span class="o">-</span><span class="n">jars</span>
</span></code></pre></td></tr></table></div></figure>


<p>If multiple files share the same relative path the default strategy is to verify that all candidates have the same contents and error out otherwise. This behavior can be configured for Spark projects using assembly-merge-strategy as follows.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">mergeStrategy</span> <span class="n">in</span> <span class="n">assembly</span> <span class="o">&lt;&lt;=</span> <span class="o">(</span><span class="n">mergeStrategy</span> <span class="n">in</span> <span class="n">assembly</span><span class="o">)</span> <span class="o">{</span> <span class="o">(</span><span class="n">old</span><span class="o">)</span> <span class="k">=&gt;</span>
</span><span class='line'>  <span class="o">{</span>
</span><span class='line'>    <span class="k">case</span> <span class="nc">PathList</span><span class="o">(</span><span class="s">&quot;javax&quot;</span><span class="o">,</span> <span class="s">&quot;servlet&quot;</span><span class="o">,</span> <span class="n">xs</span> <span class="k">@</span> <span class="k">_</span><span class="o">*)</span> <span class="k">=&gt;</span> <span class="nc">MergeStrategy</span><span class="o">.</span><span class="n">last</span>
</span><span class='line'>    <span class="k">case</span> <span class="nc">PathList</span><span class="o">(</span><span class="s">&quot;org&quot;</span><span class="o">,</span> <span class="s">&quot;apache&quot;</span><span class="o">,</span> <span class="n">xs</span> <span class="k">@</span> <span class="k">_</span><span class="o">*)</span> <span class="k">=&gt;</span> <span class="nc">MergeStrategy</span><span class="o">.</span><span class="n">last</span>
</span><span class='line'>    <span class="k">case</span> <span class="nc">PathList</span><span class="o">(</span><span class="s">&quot;com&quot;</span><span class="o">,</span> <span class="s">&quot;esotericsoftware&quot;</span><span class="o">,</span> <span class="n">xs</span> <span class="k">@</span> <span class="k">_</span><span class="o">*)</span> <span class="k">=&gt;</span> <span class="nc">MergeStrategy</span><span class="o">.</span><span class="n">last</span>
</span><span class='line'>    <span class="k">case</span> <span class="s">&quot;about.html&quot;</span> <span class="k">=&gt;</span> <span class="nc">MergeStrategy</span><span class="o">.</span><span class="n">rename</span>
</span><span class='line'>    <span class="k">case</span> <span class="n">x</span> <span class="k">=&gt;</span> <span class="n">old</span><span class="o">(</span><span class="n">x</span><span class="o">)</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>From the root folder run</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">sbt</span><span class="o">/</span><span class="n">sbt</span> <span class="n">assembly</span>
</span></code></pre></td></tr></table></div></figure>


<p>the assembly plugin then packs the class files and all the dependencies into a single JAR file: target/scala_2.10/TwitterPopularTags-assembly-0.3.0.jar.</p>

<p>You can find an example project from <a href="https://github.com/prabeesh/SparkTwitterAnalysis">here</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Standalone Spark Application in Scala]]></title>
    <link href="http://blog.prabeeshk.com/blog/2014/04/01/a-standalone-spark-application-in-scala/"/>
    <updated>2014-04-01T22:56:00+05:30</updated>
    <id>http://blog.prabeeshk.com/blog/2014/04/01/a-standalone-spark-application-in-scala</id>
    <content type="html"><![CDATA[<p>Sharing  some ideas about how to create a Spark-streaming stand-alone application and how to run the Spark applications in scala-SDK (Eclipse IDE).</p>

<h2>Building Spark Application using SBT</h2>

<p>A Standalone application in Scala using Apache Spark API. The application is build using Simple Build Tool(SBT).</p>

<p>For  creating a stand alone app take the twitter popular tag <a href="https://github.com/apache/spark/blob/branch-0.9/examples/src/main/scala/org/apache/spark/streaming/examples/TwitterPopularTags.scala">example</a></p>

<p>This program calculates popular hashtags (popular topics) over sliding 10 and 60 second windows from a Twitter stream. The stream is instantiated with credentials and optionally filters supplied by the command line arguments.</p>

<p>But here modified the code for talking twitter authentication credentials through command line argument. So it needs to give the arguments as <master> <consumerKey> <consumerSecret> <accessToken> <accessTokenSecret> <filters>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='Scala'><span class='line'><span class="c1">// Twitter Authentication credentials  </span>
</span><span class='line'><span class="nc">System</span><span class="o">.</span><span class="n">setProperty</span><span class="o">(</span><span class="s">&quot;twitter4j.oauth.consumerKey&quot;</span><span class="o">,</span> <span class="n">args</span><span class="o">(</span><span class="mi">1</span><span class="o">))</span>
</span><span class='line'><span class="nc">System</span><span class="o">.</span><span class="n">setProperty</span><span class="o">(</span><span class="s">&quot;twitter4j.oauth.consumerSecret&quot;</span><span class="o">,</span> <span class="n">args</span><span class="o">(</span><span class="mi">2</span><span class="o">))</span>
</span><span class='line'><span class="nc">System</span><span class="o">.</span><span class="n">setProperty</span><span class="o">(</span><span class="s">&quot;twitter4j.oauth.accessToken&quot;</span><span class="o">,</span> <span class="n">args</span><span class="o">(</span><span class="mi">3</span><span class="o">))</span>
</span><span class='line'><span class="nc">System</span><span class="o">.</span><span class="n">setProperty</span><span class="o">(</span><span class="s">&quot;twitter4j.oauth.accessTokenSecret&quot;</span><span class="o">,</span> <span class="n">args</span><span class="o">(</span><span class="mi">4</span><span class="o">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>
If you want to read twitter authentication credential from file, refer this <a href="https://github.com/pwendell/spark-twitter-collection/blob/master/TwitterUtils.scala">link</a></p>

<p>The sbt configuration file. For more detail about sbt <a href="http://www.scala-sbt.org/release/docs/Getting-Started/Setup.html">refer</a></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='Scala'><span class='line'><span class="n">name</span> <span class="o">:=</span> <span class="s">&quot;TwitterPopularTags&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="n">version</span> <span class="o">:=</span> <span class="s">&quot;0.1.0&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="n">scalaVersion</span> <span class="o">:=</span> <span class="s">&quot;2.10.3&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="n">libraryDependencies</span> <span class="o">++=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">&quot;org.apache.spark&quot;</span> <span class="o">%%</span>
</span><span class='line'><span class="s">&quot;spark-core&quot;</span> <span class="o">%</span> <span class="s">&quot;0.9.0-incubating&quot;</span><span class="o">,</span>
</span><span class='line'><span class="s">&quot;org.apache.spark&quot;</span> <span class="o">%%</span> <span class="s">&quot;spark-streaming&quot;</span> <span class="o">%</span> <span class="s">&quot;0.9.0-incubating&quot;</span><span class="o">,</span>
</span><span class='line'><span class="s">&quot;org.apache.spark&quot;</span> <span class="o">%%</span> <span class="s">&quot;spark-streaming-twitter&quot;</span> <span class="o">%</span> <span class="s">&quot;0.9.0-incubating&quot;</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">resolvers</span> <span class="o">+=</span> <span class="s">&quot;Akka Repository&quot;</span> <span class="n">at</span> <span class="s">&quot;http://repo.akka.io/releases/&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<p>You can find the project from <a href="https://github.com/prabeesh/SparkTwitterAnalysis/tree/0.1.0">here</a></p>

<h2>Spark programming in Eclipse</h2>

<p>Using sbt eclipse plugin, sbt project can run on Eclipse IDE.  For more details find <a href="https://github.com/typesafehub/sbteclipse">here</a></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='Scala'><span class='line'><span class="n">addSbtPlugin</span><span class="o">(</span><span class="s">&quot;com.typesafe.sbteclipse&quot;</span> <span class="o">%</span> <span class="s">&quot;sbteclipse-plugin&quot;</span> <span class="o">%</span> <span class="s">&quot;2.1.0&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>then run from root folder of the project</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='Scala'><span class='line'><span class="n">sbt</span><span class="o">/</span><span class="n">sbt</span> <span class="n">eclipse</span>
</span></code></pre></td></tr></table></div></figure>


<p>This command  creates a project compatible with Eclipse. Upon opening the eclipse IDE this project can now be imported and the executed with spark.</p>

<p>You can find the sbt eclipse project from <a href="https://github.com/prabeesh/SparkTwitterAnalysis/tree/0.2.0">here</a></p>

<p>To avoid generating eclipse source entries for the java directories and put all libs in the lib_managed directory, that way we can distribute eclipse project files, for this - add the contents to build.sbt</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='Scala'><span class='line'><span class="cm">/*put all libs in the lib_managed directory, </span>
</span><span class='line'><span class="cm">that way we can distribute eclipse project files</span>
</span><span class='line'><span class="cm">*/</span>
</span><span class='line'>
</span><span class='line'><span class="n">retrieveManaged</span> <span class="o">:=</span> <span class="kc">true</span>
</span><span class='line'>
</span><span class='line'><span class="nc">EclipseKeys</span><span class="o">.</span><span class="n">relativizeLibs</span> <span class="o">:=</span> <span class="kc">true</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// Avoid generating eclipse source entries for the java directories</span>
</span><span class='line'>
</span><span class='line'><span class="o">(</span><span class="n">unmanagedSourceDirectories</span> <span class="n">in</span> <span class="nc">Compile</span><span class="o">)</span> <span class="o">&lt;&lt;=</span> <span class="o">(</span><span class="n">scalaSource</span> <span class="n">in</span> <span class="nc">Compile</span><span class="o">)(</span><span class="nc">Seq</span><span class="o">(</span><span class="k">_</span><span class="o">))</span>
</span><span class='line'>
</span><span class='line'><span class="o">(</span><span class="n">unmanagedSourceDirectories</span> <span class="n">in</span> <span class="nc">Test</span><span class="o">)</span> <span class="o">&lt;&lt;=</span> <span class="o">(</span><span class="n">scalaSource</span> <span class="n">in</span> <span class="nc">Test</span><span class="o">)(</span><span class="nc">Seq</span><span class="o">(</span><span class="k">_</span><span class="o">))</span>
</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Installing Apache Spark on Ubuntu-12.04]]></title>
    <link href="http://blog.prabeeshk.com/blog/2013/11/26/installing-apache-spark-on-ubuntu-1204/"/>
    <updated>2013-11-26T12:24:00+05:30</updated>
    <id>http://blog.prabeeshk.com/blog/2013/11/26/installing-apache-spark-on-ubuntu-1204</id>
    <content type="html"><![CDATA[<p>Apache Spark is an open source in memory cluster computing framework. Initially developed in UC Berkely AMPLab and now an Apache Incubator Project.    Spark is a cluster computing framework designed for low-latency iterative jobs and interactive use from an interpreter. It provides clean, language-integrated APIs in Scala, Java, and Python, with a rich array of parallel operators. You may read more about it <a href="http://spark.apache.org/">here</a></p>

<p>You can download the Apache Spark distribution(0.8.0-incubating) from <a href="http://d3kbcqa49mib13.cloudfront.net/spark-0.8.0-incubating.tgz">here</a>. After that untar the downloaded file.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ tar xvf spark-0.8.0-incubating.tgz</span></code></pre></td></tr></table></div></figure>


<p>You need to have Scala installed, or the SCALA_HOME environment variable pointing to a Scala installation.</p>

<h3>Building</h3>

<p>SBT(Simple Build Tool) is used for building Spark, which is bundled with it. To compile the code</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ cd spark-0.8.0-incubating
</span><span class='line'>
</span><span class='line'>$sbt/sbt assembly</span></code></pre></td></tr></table></div></figure>


<p>Building take some time. After successfully packing you can test a sample program</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$./run-example org.apache.spark.examples.SparkPi local</span></code></pre></td></tr></table></div></figure>


<p>Then you get the output as
Pi is roughly 3.14634. Spark is ready to fire</p>

<h3>Spark Interactive Shell</h3>

<p>You can run Spark interactively through the Scala shell</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$./spark-shell</span></code></pre></td></tr></table></div></figure>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="n">textFile</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;README.md&quot;</span><span class="o">)</span>
</span><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="n">textFile</span><span class="o">.</span><span class="n">count</span><span class="o">()</span>
</span></code></pre></td></tr></table></div></figure>


<p>Using this you can check your code line by line.</p>

<h3>Accessing Hadoop Filesystems</h3>

<p>You can run Spark along with your existing Hadoop Cluster. To access Hadoop data from Spark, just use a hdfs://URL.  Run a word count example in the shell, taking input from hdfs and writing output back to hdfs. For using hdfs you must rebuild Spark against the same version that your hdfs cluster uses. From the Spark download page, you may download a prebuilt package.
If you have already the build source package, rebuild it against the hadoop version as follows</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="nc">$sbt</span><span class="o">/</span><span class="n">sbt</span> <span class="n">clean</span>
</span></code></pre></td></tr></table></div></figure>


<p>You can change this by setting the SPARK_HADOOP_VERSION variable. Here uses Hadoop 2.0.0-cdh4.3.0</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="nc">$SPARK_HADOOP_VERSION</span><span class="k">=</span><span class="mf">2.0</span><span class="o">.</span><span class="mi">0</span><span class="o">-</span><span class="n">mr1</span><span class="o">-</span><span class="n">cdh4</span><span class="o">.</span><span class="mf">3.0</span> <span class="n">sbt</span><span class="o">/</span><span class="n">sbt</span> <span class="n">assembly</span>
</span></code></pre></td></tr></table></div></figure>


<p>After successfully build. You can read  and write data into cdh4.3.0 clusters.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">$</span><span class="o">./</span><span class="n">spark</span><span class="o">-</span><span class="n">shell</span>
</span></code></pre></td></tr></table></div></figure>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="k">var</span> <span class="n">file</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;hdfs://IP:8020/path/to/textfile.txt&quot;</span><span class="o">)</span>
</span><span class='line'><span class="n">scala</span><span class="o">&gt;</span>  <span class="n">file</span><span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot;,&quot;</span><span class="o">)).</span><span class="n">map</span><span class="o">(</span><span class="n">word</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">word</span><span class="o">,</span> <span class="mi">1</span><span class="o">)).</span><span class="n">reduceByKey</span><span class="o">(</span><span class="k">_</span><span class="o">+</span><span class="k">_</span><span class="o">)</span>
</span><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="n">count</span><span class="o">.</span><span class="n">saveAsTextFile</span><span class="o">(</span><span class="s">&quot;hdfs://IP:8020/path/to/ouput&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>You may find more <a href="http://spark.apache.org/docs/latest/quick-start.html">here</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running Mesos-0.13.0 on Ubuntu-12.04]]></title>
    <link href="http://blog.prabeeshk.com/blog/2013/10/07/running-mesos-0130-on-ubuntu-1204/"/>
    <updated>2013-10-07T10:53:00+05:30</updated>
    <id>http://blog.prabeeshk.com/blog/2013/10/07/running-mesos-0130-on-ubuntu-1204</id>
    <content type="html"><![CDATA[<p>You will need the following packages to run Mesos.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sudo apt-get install python2.7-dev g++ libcppunit-dev libunwind7-dev git libcurl4-nss-dev</span></code></pre></td></tr></table></div></figure>


<p>You need to have Java installed, or the JAVA_HOME environment variable pointing to a Java installation.</p>

<p>You can download the Mesos distribution from <a href="http://www.apache.org/dyn/closer.cgi/mesos/0.13.0/">here</a>. After that untar the downloaded file</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ tar xvf mesos-0.13.0.tar.gz</span></code></pre></td></tr></table></div></figure>


<h3>Building and Installing</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ cd mesos-0.13.0
</span><span class='line'>$ mkdir build
</span><span class='line'>$ cd build
</span><span class='line'>$ sudo  ../configure --prefix=/home/user/mesos
</span><span class='line'>$ sudo make
</span><span class='line'>$ sudo make check
</span><span class='line'>$ sudo make install</span></code></pre></td></tr></table></div></figure>


<p>You can pass the &ndash;prefix option while configuring to tell where to install. For example, pass<strong><strong>&ndash;prefix=/home/user/mesos</strong></strong>. By default the prefix is <strong><strong>/usr/local</strong></strong>.
Once you are done with the installation, it is now time to start your mesos cluster:</p>

<p>Go into the directory where you built Mesos.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ cd mesos-0.13.0/build/bin</span></code></pre></td></tr></table></div></figure>


<p>Run the command to launch the master.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sh mesos-master.sh </span></code></pre></td></tr></table></div></figure>


<p>
Take note of the IP and port that the master is running on, which will look something like <strong><strong>[IP of the machine]:5050</strong></strong>.
URL of master: <strong>mesos://[IP of the machine]:5050</strong>. View the master&rsquo;s web UI at <strong><code>http://[IP of the machine]:5050</code></strong>.</p>

<p>Copy mesos-0.13.0 and mesos to the same paths on all the nodes in the cluster. To launch a slave go to the directory</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ cd mesos-0.13.0/build/src</span></code></pre></td></tr></table></div></figure>


<p>Run the command to launch the slave.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sh mesos-slave  --master=[IP of the mesos master machine ]:5050</span></code></pre></td></tr></table></div></figure>


<p>The slave will show up on the mesos master&rsquo;s web UI.</p>

<h3>Mesos Client</h3>

<p>Copy the libmesos.so from prefix folder(/home/user/mesos/lib) of the mesos master to /usr/local/lib of the client machine and install the following package</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sudo apt-get install libunwind7-dev</span></code></pre></td></tr></table></div></figure>


<p>
Now you can  run  applications against the Mesos cluster from client machine.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MQTT Scala Publisher and Subscriber Using Eclipse Paho]]></title>
    <link href="http://blog.prabeeshk.com/blog/2013/08/26/mqtt-scala-publisher-and-subscriber/"/>
    <updated>2013-08-26T09:41:00+05:30</updated>
    <id>http://blog.prabeeshk.com/blog/2013/08/26/mqtt-scala-publisher-and-subscriber</id>
    <content type="html"><![CDATA[<p>MQTT is a machine-to-machine (M2M)/Internet of Things connectivity protocol. It was designed with extremely lightweight that support embedded and low power processing device. You may read more about it <a href="http://mqtt.org/">here</a>. MQTT is broker based message queuing system. To work with Mqtt, Mqtt Message broker/server required. <a href="http://mosquitto.org/">Mosquitto</a> is an open source Mqtt Broker. In ubuntu mosquitto can be installed using the command</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sudo apt-get install mosquitto</span></code></pre></td></tr></table></div></figure>


<p>Eclipse Paho is one mqtt client work well with mosquitto. You may read more about it <a href="http://www.eclipse.org/paho/">here</a>.</p>

<p>MQTT Scala subscriber and publisher code based on eclipse paho library 0.4.0 is available in <a href="https://github.com/prabeesh/MQTTScalaClient">github</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Paint App Using Flask With MongoDB]]></title>
    <link href="http://blog.prabeeshk.com/blog/2013/03/31/paint-app-using-flask-with-mongodb/"/>
    <updated>2013-03-31T21:53:00+05:30</updated>
    <id>http://blog.prabeeshk.com/blog/2013/03/31/paint-app-using-flask-with-mongodb</id>
    <content type="html"><![CDATA[<p>Here the paint app is modified using with a new database system. The MongoDB, is a famous NoSQL database system. The NoSQL database is a simple lightweight mechanism. It provides high scalability and availability. It provides horizontal scaling of data. This system redefined the database concept from the traditional relational database system.
   MongoDB is an open-source, document-oriented database designed for ease of development and scaling. The main features of MongoDB are flexibility, power, speed, and ease of use. The MongoDB can installed in local machine by following the instructions from <a href="http://docs.mongodb.org/manual/installation/">official website</a></p>

<p>Some commands used in the MonoDB operations are given below:</p>

<p>  <code>db</code> :- After starting the mongo shell your session will use the test database for context, by default. At any time issue the above operation at the mongo to report the current database.
  <code>show dbs</code> :- Display the list of databases from the mongo shell.
  <code>use mydb</code> :- Switch to a new database named mydb.
  <code>help</code> :- At any point you can access help for the mango shell using thisoperation.
  <code>db.things.insert()</code> :- Insert documents into the collection things.When you insert the first document, the mangod will create both the database and the things collection.
  <code>show collections</code> :- Displays the available collections in the database.
  <code>db.things.find()</code> :- Finds the documents in the collection. The documents to be found can be specified through arguments of the find function. The cursor of the MongoDB displays only the first 20 output documents. it command is used to display the rest of the documents.</p>

<p>The source code is available in <a href="https://github.com/prabeesh/Paintapp-Javascript-Canvas-Flask-MongoDB">github</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Paint App Using JavaScript and Canvas]]></title>
    <link href="http://blog.prabeeshk.com/blog/2013/03/30/paint-app-using-javascript-and-canvas/"/>
    <updated>2013-03-30T12:44:00+05:30</updated>
    <id>http://blog.prabeeshk.com/blog/2013/03/30/paint-app-using-javascript-and-canvas</id>
    <content type="html"><![CDATA[<p>An application to draw simple drawings using lines, rectangles and circles in different colours.</p>

<p><img class="center" src="http://blog.prabeeshk.com/images/paint.png" width="850" height="350" title="image" alt="images"></p>

<p>The application is developed using JavaScript and HTML5. The canvas feature in HTML5 is used for providing a drawable region. The JavaScript is used to handle drawing functions in these region. The select button to select the different tools to draw. The colour picker is made using the button option. The script basically listen three mouse events mousedown, mousemove and mouseup. This application implemented using two different frameworks Google App Engine and Flask.</p>

<h3>Application with saving facility</h3>

<p>This is done by saving values about each object needed to regenerate the same drawing. When we click the save button the data is transferred to the server as a json string where it is stored along with a name provided by the user. Simply regenerate the drawing using the data received from the server.</p>

<p>In Google App Engine Google data storage is used for data storage. But in Flask sqlite3 is used for data storage.</p>

<p>Source code: <a href="https://github.com/prabeesh/Paintapp-Javascript-Canvas-GAE">App with GAE</a> and <a href="https://github.com/prabeesh/Paintapp-Javascript-Canvas-Flask">App with Flask</a></p>

<p>The app is deployed in appspot.com, You can find the application <a href="http://prabs-paint.appspot.com/">here</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Simple CUDA Program]]></title>
    <link href="http://blog.prabeeshk.com/blog/2013/03/07/a-simple-cuda-program/"/>
    <updated>2013-03-07T11:00:00+05:30</updated>
    <id>http://blog.prabeeshk.com/blog/2013/03/07/a-simple-cuda-program</id>
    <content type="html"><![CDATA[<p>Let&rsquo;s consider a simple example CUDA code to compute squares of 64 numbers. A typical GPU program consist of following steps.</p>

<pre><code>1- CPU allocates storage on GPU
2- CPU copies input data from CPU to GPU
3- CPU launch kernels on GPU to process the data
4- CPU copies result back to CPU from GPU
</code></pre>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="n">nvcc</span> <span class="o">-</span><span class="n">o</span> <span class="n">square</span> <span class="n">square</span><span class="p">.</span><span class="n">cu</span>
</span></code></pre></td></tr></table></div></figure>


<p>Here is instead of running the regular C compiler we are running <em>nvcc</em>, the Nvidia C Compiler. The output is going to go an executable called square and our input file is &ldquo;square.cu&rdquo;. cu is the convention for how we name.Source code is available in <a href="https://github.com/prabeesh/CUDA-code-square/blob/master/square.cu">github</a></p>

<p>We are going to walk through the CPU code first.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="k">const</span> <span class="kt">int</span> <span class="n">ARRAY_SIZE</span> <span class="o">=</span> <span class="mi">64</span><span class="p">;</span>
</span><span class='line'>    <span class="k">const</span> <span class="kt">int</span> <span class="n">ARRAY_BYTES</span> <span class="o">=</span> <span class="n">ARRAY_SIZE</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span>
</span><span class='line'>    <span class="c1">// generate the input array on the host float h_in[ARRAY_SIZE]; </span>
</span><span class='line'>    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="n">ARRAY_SIZE</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>        <span class="n">h_in</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="kt">float</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="kt">float</span> <span class="n">h_out</span><span class="p">[</span><span class="n">ARRAY_SIZE</span><span class="p">]</span>
</span><span class='line'><span class="p">....</span>
</span><span class='line'><span class="p">.....</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The first thing we are going to do is declare the size of the array and determine how many bytes it uses. We then fill it up in this loop with floating point numbers, where array element i is simply set to i. All of this is standard C, nothing GPU specific so far. One thing to note, though, is a common CUDA convention. Data on the CPU, the host, starts with h. Data on the GPU, the device, starts with d. This is just a convention.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="c1">// declare GPU memory pointers </span>
</span><span class='line'><span class="kt">float</span> <span class="o">*</span> <span class="n">d_in</span><span class="p">;</span>
</span><span class='line'><span class="kt">float</span> <span class="o">*</span> <span class="n">d_out</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>If you&rsquo;re accessing data through a point or on the CPU, your pointer better point to something in CPU memory, or you&rsquo;re going to have a bad time. Same thing for the GPU. And the first interesting thing that you see is how to declare a pointer on the GPU. It looks just like a pointer declared on the CPU. It&rsquo;s just a float star.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="c1">// allocate GPU memory </span>
</span><span class='line'><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span> <span class="o">&amp;</span><span class="n">d_in</span><span class="p">,</span> <span class="n">ARRAY_BYTES</span><span class="p">);</span>
</span><span class='line'><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span> <span class="o">&amp;</span><span class="n">d_out</span><span class="p">,</span> <span class="n">ARRAY_BYTES</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now, to tell Cuda that your data is actually on the GPU, not the CPU. We are using cudaMalloc with two arguments, the pointer and the number of bytes to allocate. cudaMalloc means allocate the data on the GPU whereas, a plain Malloc would mean allocate the data on a CPU.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="c1">// transfer the array to the GPU </span>
</span><span class='line'><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">h_in</span><span class="p">,</span> <span class="n">ARRAY_BYTES</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>The next thing we do is actually copy the data from the CPU the array h_in on to the GPU, the array din. This call is cudaMemcpy. It&rsquo;s just like a regular Memcpy, but it takes four arguments instead of three. The first three arguments are the same as regular C Memcpy, the destination, the source, and the number of bytes. The fourth argument says the direction of the transfer. The three choices are Cuda memory host to device, Cuda memory device to host, and Cuda memory device to device.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="c1">// launch the kernel </span>
</span><span class='line'><span class="n">square</span><span class="o">&lt;&lt;&lt;</span><span class="n">dim3</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">dim3</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_out</span><span class="p">,</span> <span class="n">d_in</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now consider how do we actually launch kernal on the GPU. So, here is a new piece of syntax in CUDA, the CUDA launch operator. So, the CUDA launch operator</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="o">&lt;&lt;&lt;</span><span class="n">someparameters</span><span class="o">&gt;&gt;&gt;</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>So, this line says, launch the kernel name square on one block of 64 elements. Then, the arguments to the kernel are two pointers, d_out and d_in. This code tells the CPU to launch on the GPU 64 copies of the kernel on 64 threads. Note that we can only call the kernel on GPU data, not CPU data. And this cudaMemcpy call will move memory from device to host, and place it in h_out.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="c1">// print out the resulting array </span>
</span><span class='line'><span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="p">;</span> <span class="n">ARRAY_SIZE</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">printf</span><span class="p">(</span><span class="s">&quot;%f&quot;</span><span class="p">,</span> <span class="n">h_out</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span><span class='line'>    <span class="n">printf</span><span class="p">(((</span><span class="n">i</span> <span class="o">%</span> <span class="mi">4</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">)</span> <span class="o">?</span> <span class="s">&quot;</span><span class="se">\t</span><span class="s">&quot;</span> <span class="o">:</span> <span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_in</span><span class="p">);</span> <span class="n">c</span>
</span><span class='line'>    <span class="nf">udaFree</span><span class="p">(</span><span class="n">d_out</span><span class="p">);</span>
</span><span class='line'>    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>The next thing we do is print it out. We are just walking through the h_out array, we are printing four things per line, so we are;putting tabs in and then a new line after four, and then we free the memory that we allocated on the GPU and return 0. So, that&rsquo;s all the CPU code.; ;Most programs are going to have you create some data on the CPU, allocate;some data on the GPU, copy memory from CPU to GPU, launch some kernels that will run on the GPU, copy the result back to the CPU and then, continue;to process them, print them, and so on.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">square</span><span class="p">(</span><span class="kt">float</span> <span class="o">*</span> <span class="n">d_out</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span> <span class="n">d_in</span><span class="p">){</span>
</span><span class='line'>    <span class="kt">int</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span><span class='line'>    <span class="kt">float</span> <span class="n">f</span> <span class="o">=</span> <span class="n">d_in</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
</span><span class='line'>    <span class="n">d_out</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span> <span class="o">*</span> <span class="n">f</span><span class="p">;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now let&rsquo;s look at the kernel itself. Recall that this will look like a serial program that will run on one thread. And the CPU is responsible for launching that;program on many parallel threads. This kernel indeed looks exactly like a serial program.</p>

<p>Just know that this is the way;that CUDA knows this code is a kernel as opposed to CPU code. Next we have void. Void just means the kernel doesn&rsquo;t return a value. Instead it writes the;output into the pointer specified in its argument list. This kernel takes two arguments. These are pointers to the output and the input arrays.</p>

<p>Let&rsquo;s walk through the body of the kernel. So the first line of the body here. CUDA has a built in variable called thread index, threadIDX, and that&rsquo;s going to tell each thread its index within a block. threadIDX is actually a c struct with 3 members. .x, .y, and .z. the c struct is called a dim 3. Now, we will launch 64 threads. So for the first instance of those threads, threadIDX.x will return zero, for the second instance, 1. And so on, up to 63 for the last element. Everything else in this kernel just looks like straightforward C. It looks just like a serial program.</p>

<p>For each thread, we&rsquo;re going to first read the array element corresponding to this thread index from global memory. We are going to store it in this float;variable f. We are then going to square f, and we&rsquo;re going to write that value back to global memory, in the output array element that corresponds to our thread index.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running Arduino Codes in Stand Alone Atmega8]]></title>
    <link href="http://blog.prabeeshk.com/blog/2012/07/14/running-arduino-codes-in-stand-alone/"/>
    <updated>2012-07-14T02:23:00+05:30</updated>
    <id>http://blog.prabeeshk.com/blog/2012/07/14/running-arduino-codes-in-stand-alone</id>
    <content type="html"><![CDATA[<p>An Arduino board consists of an 8-bit Atmel AVR microcontroller with complementary components to facilitate programming and incorporation into other circuits.
If you wish to study the arduino codes ,then one of the major problems is the availability and cost of the Arduino board. If you have an atmega8 microcontroller  then you have to study the Arduino codes by simply changing some options in Arduino IDE.</p>

<p>First download the arduino IDE(I am using Arduino 1.0). Next you have to an avr  programmer(I am using usbasp and usbtiny).
Launch the arduino IDE as root.Then select your programmer from tools and also select your board  in this case select ATmega8.
Take care in fuse bytes because arduino codes are running in 8MHz.Y ou can enable internal 8MHz clock by</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="o">-</span><span class="n">U</span> <span class="nl">lfuse</span><span class="p">:</span><span class="nl">w</span><span class="p">:</span><span class="mh">0xa4</span><span class="o">:</span><span class="n">m</span> <span class="o">-</span><span class="n">U</span> <span class="nl">hfuse</span><span class="p">:</span><span class="nl">w</span><span class="p">:</span><span class="mh">0xcc</span><span class="o">:</span><span class="n">m</span>
</span></code></pre></td></tr></table></div></figure>


<p>Or you can enable the external crystal by setting the fuse byte as</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='c'><span class='line'><span class="o">-</span><span class="n">U</span> <span class="nl">lfuse</span><span class="p">:</span><span class="nl">w</span><span class="p">:</span><span class="mh">0xef</span><span class="o">:</span><span class="n">m</span>
</span></code></pre></td></tr></table></div></figure>


<p>and put a  8MHz crystal.</p>

<p>You can find mapping between atmega8 and arduino here</p>

<p><img class="center" src="http://blog.prabeeshk.com/images/arduino.png" width="600" height="350" title="image" alt="images"></p>
]]></content>
  </entry>
  
</feed>
